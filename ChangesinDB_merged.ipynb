{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9e5cd72-56a6-4410-9057-ad48a9d74058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in c:\\users\\91700\\anaconda3\\envs\\se4g24\\lib\\site-packages (2.9.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "187e6e8a-0915-47c9-a1dd-e3e73980956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, Column, Integer, String, Float\n",
    "from config import db_name, user, password, host\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from geoalchemy2 import Geometry\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely import wkt\n",
    "import psycopg2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d38454a-7ffd-482f-a070-d1e1692a6297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b846d530-90e2-47e3-bcc8-47da7cd5e9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send the request\n",
    "def jason2dataf(url):\n",
    "    response = requests.get(url)\n",
    "    response\n",
    "    # store the raw text of the response in a variable\n",
    "    raw_data = response.text\n",
    "    raw_data\n",
    "    # parse the raw text response into a JSON\n",
    "    data = json.loads(raw_data)\n",
    "    data\n",
    "    # from JSON to Pandas DataFrame\n",
    "    data_df = pd.json_normalize(data)\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dda643da-89be-439b-86e2-b86aff4149ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch and convert data from the ISPRA Idrogeo API for the Lombardy region and its provinces into DataFrames.\n",
    "# The jason2dataf function takes a URL endpoint as an argument, makes a request to the API,\n",
    "# retrieves the JSON data, and converts it into a pandas DataFrame for further analysis.\n",
    "dataf_lombardia = jason2dataf('https://test.idrogeo.isprambiente.it/api/pir/regioni/3')\n",
    "data_prov_milan = jason2dataf('https://test.idrogeo.isprambiente.it/api/pir/province/15')\n",
    "data_prov_varese = jason2dataf('https://test.idrogeo.isprambiente.it/api/pir/province/12')\n",
    "data_prov_como = jason2dataf('https://test.idrogeo.isprambiente.it/api/pir/province/13')\n",
    "data_prov_lecco = jason2dataf('https://test.idrogeo.isprambiente.it/api/pir/province/97')\n",
    "data_prov_sondrio = jason2dataf('https://test.idrogeo.isprambiente.it/api/pir/province/14')\n",
    "data_prov_bergamo = jason2dataf('https://test.idrogeo.isprambiente.it/api/pir/province/16')\n",
    "data_prov_brescia = jason2dataf('https://test.idrogeo.isprambiente.it/api/pir/province/17')\n",
    "data_prov_pavia = jason2dataf('https://test.idrogeo.isprambiente.it/api/pir/province/18')\n",
    "data_prov_cremona = jason2dataf('https://test.idrogeo.isprambiente.it/api/pir/province/19')\n",
    "data_prov_mantova = jason2dataf('https://test.idrogeo.isprambiente.it/api/pir/province/20')\n",
    "data_prov_lodi = jason2dataf('https://test.idrogeo.isprambiente.it/api/pir/province/98')\n",
    "data_prov_Monza = jason2dataf('https://test.idrogeo.isprambiente.it/api/pir/province/108')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e818c8ed-2ab7-4820-b001-98134f0dfe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames\n",
    "merged_df = pd.concat([data_prov_milan, data_prov_varese,data_prov_como,data_prov_lecco,data_prov_sondrio,data_prov_bergamo,data_prov_brescia,data_prov_pavia,data_prov_cremona,data_prov_mantova,data_prov_lodi,data_prov_Monza]).reset_index(drop=True)\n",
    "\n",
    "# Rename the 'cod_prov' column to 'COD_PROV' to maintain consistency in column naming conventions.\n",
    "merged_df.rename(columns={'cod_prov':'COD_PROV'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b57c3a12-007d-4bd9-a9fe-043f4efecb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file paths for the shapefiles of the region and provinces.\n",
    "# These shapefiles contain the geographical boundaries for the Lombardy region and its provinces.\n",
    "shapefile_path_region = \"./Limiti01012024_g/Reg01012024_g/Reg01012024_g_WGS84.shp\"\n",
    "shapefile_path_province = \"./Limiti01012024_g/ProvCM01012024_g/ProvCM01012024_g_WGS84.shp\"\n",
    "\n",
    "# Use Geopandas to read the shapefiles into GeoDataFrames.\n",
    "gdf_region = gpd.read_file(shapefile_path_region)\n",
    "gdf_province = gpd.read_file(shapefile_path_province)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73c50bbe-6c91-460c-bfc6-67b6cce0a2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the list of desired province codes (COD_PROV) for filtering.\n",
    "# These codes correspond to the provinces within the Lombardy region that we are interested in.\n",
    "desired_cod_RIP = [15, 12, 13, 97, 14, 16, 17, 18, 19, 20, 98, 108]\n",
    "\n",
    "# Filter the GeoDataFrame based on the desired cod_RIP values\n",
    "filtered_gdf = gdf_province[gdf_province['COD_PROV'].isin(desired_cod_RIP)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5938a7ec-c514-47c1-bb81-77c38c04029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separate the 'geometry' column from the filtered GeoDataFrame\n",
    "geometry = filtered_gdf.pop('geometry')\n",
    "\n",
    "# Create a new GeoDataFrame by combining the filtered data with the 'geometry' column\n",
    "filtered_gdf3 = gpd.GeoDataFrame(filtered_gdf, geometry=geometry)\n",
    "\n",
    "# Merge the new GeoDataFrame with the previously merged DataFrame on the 'COD_PROV' column\n",
    "# Use a left join to ensure all rows from the GeoDataFrame are kept, adding data from the merged DataFrame\n",
    "merged_df3 = pd.merge(filtered_gdf3, merged_df, on='COD_PROV', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec485f21-f8c6-4ad4-aff6-94225c4431ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GeoDataFrame from the merged DataFrame, specifying the 'geometry' column\n",
    "merged_gdf = gpd.GeoDataFrame(merged_df3, geometry='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "501e042c-2f8d-418d-90d0-667e1339d9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of columns to select from the merged GeoDataFrame\n",
    "columns_to_select =  ['geometry','cod_reg','cod_rip','COD_PROV','ar_kmq','nome','uid',\n",
    "    'ar_fr_p3p4', 'ar_fr_p2', 'ar_fr_p1', 'ar_fr_p3' , 'ar_fr_p4' , 'ar_fr_aa', 'ar_frp4_p','ar_frp3_p', 'ar_frp2_p', \n",
    "    'ar_frp1_p','ar_fraa_p', 'ar_frp3p4p',\n",
    "    'pop_fr_p2', 'pop_fr_p1', 'pop_fr_p3', 'pop_fr_p4', 'pop_fr_aa','popfrp4_p','popfrp3_p','popfrp2_p','popfrp1_p', \n",
    "    'popfrp3p4p', 'popfr_p3p4' , 'popfraa_p', 'ed_fr_p3', 'ed_fr_p4',\n",
    "    'ed_fr_p2', 'ed_fr_p1', \n",
    "    'ed_fr_p3p4', 'edfrp3p4p'\n",
    "]\n",
    "\n",
    "# Select the specified columns from the merged GeoDataFrame\n",
    "selected_df = merged_gdf[columns_to_select]\n",
    "\n",
    "# Create a copy of the selected DataFrame for further processing\n",
    "selected_df2 = selected_df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11ed99b8-3d45-4f60-86e9-d8e38033a6f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "could not translate host name \"http://database-test1.cnuw2qoiq9mr.eu-north-1.rds.amazonaws.com\" to address: No such host is known. \n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Connect to the default database to create the new database\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[43mpsycopg2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdbname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdb_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpassword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m conn\u001b[38;5;241m.\u001b[39mautocommit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;66;03m# needed to create a db programmatically\u001b[39;00m\n\u001b[0;32m      4\u001b[0m cursor \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mcursor()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\se4g24\\Lib\\site-packages\\psycopg2\\__init__.py:122\u001b[0m, in \u001b[0;36mconnect\u001b[1;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     kwasync[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    121\u001b[0m dsn \u001b[38;5;241m=\u001b[39m _ext\u001b[38;5;241m.\u001b[39mmake_dsn(dsn, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 122\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_factory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwasync\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     conn\u001b[38;5;241m.\u001b[39mcursor_factory \u001b[38;5;241m=\u001b[39m cursor_factory\n",
      "\u001b[1;31mOperationalError\u001b[0m: could not translate host name \"http://database-test1.cnuw2qoiq9mr.eu-north-1.rds.amazonaws.com\" to address: No such host is known. \n"
     ]
    }
   ],
   "source": [
    "# Connect to the default database to create the new database\n",
    "conn = psycopg2.connect(dbname=db_name, user=user, password=password, host=host)\n",
    "conn.autocommit = True # needed to create a db programmatically\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create the new database\n",
    "try:\n",
    "    cursor.execute(f\"CREATE DATABASE {db_name};\")\n",
    "except:\n",
    "    pass  # If the database already exists, ignore the error\n",
    "\n",
    "# Close the connection to the default database\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0227037-dd9f-4760-bdc4-59c2bf378e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.wkb import loads as wkb_loads\n",
    "from shapely.wkt import dumps as wkt_dumps\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import Column, Integer, String, Text, create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "# Define the Base class for SQLAlchemy\n",
    "Base = declarative_base()\n",
    "\n",
    "# Define your SQLAlchemy model\n",
    "class Dataset(Base):\n",
    "    __tablename__ = 'dataset'\n",
    "\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    cod_reg = Column(Integer)\n",
    "    cod_rip = Column(Integer)\n",
    "    cod_prov = Column(Integer)\n",
    "    ar_kmq = Column(Float)\n",
    "    nome = Column(String)\n",
    "    uid = Column(Integer)\n",
    "    ar_fr_p3p4 = Column(Float)\n",
    "    ar_fr_p2 = Column(Float)\n",
    "    ar_fr_p1 = Column(Float)\n",
    "    ar_fr_p3 = Column(Float)\n",
    "    ar_fr_p4 = Column(Float)\n",
    "    ar_fr_aa = Column(Float)\n",
    "    ar_frp3p4p = Column(Float)\n",
    "    ar_frp4_p = Column(Float)\n",
    "    ar_frp3_p = Column(Float)\n",
    "    ar_frp2_p = Column(Float)\n",
    "    ar_frp1_p = Column(Float)\n",
    "    ar_fraa_p = Column(Float)\n",
    "    pop_fr_p2 = Column(Float)\n",
    "    pop_fr_p1 = Column(Float)\n",
    "    pop_fr_p3 = Column(Float)\n",
    "    pop_fr_p4 = Column(Float)\n",
    "    popfr_p3p4 = Column(Float)\n",
    "    pop_fr_aa = Column(Float)\n",
    "    popfrp4_p = Column(Float)\n",
    "    popfrp3_p = Column(Float)\n",
    "    popfrp2_p = Column(Float)\n",
    "    popfrp1_p = Column(Float)\n",
    "    popfrp3p4p = Column(Float)\n",
    "    popfraa_p = Column(Float)\n",
    "    ed_fr_p4 = Column(Float)\n",
    "    ed_fr_p3 = Column(Float)\n",
    "    ed_fr_p2 = Column(Float)\n",
    "    ed_fr_p1 = Column(Float)\n",
    "    ed_fr_p3p4 = Column(Float)\n",
    "    edfrp3p4p = Column(Float)\n",
    "    geometry = Column(Text)  # Assuming you're storing geometry as WKT in a text column\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<Dataset(id={self.id}, nome='{self.nome}')>\" # String representation for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbab90b-169e-436a-8676-7c7da1ff1ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert WKB to WKT\n",
    "def convert_wkb_to_wkt(geom):\n",
    "    if isinstance(geom, str):\n",
    "        geom = bytes.fromhex(geom)  # Convert hex string to bytes\n",
    "    if isinstance(geom, (bytes, bytearray)):\n",
    "        return wkt_dumps(wkb_loads(geom))  # Convert WKB to Shapely geometry, then to WKT\n",
    "    elif isinstance(geom, (MultiPolygon, Polygon)):\n",
    "        return wkt_dumps(geom)  # If it's already a Shapely geometry, convert directly to WKT\n",
    "    else:\n",
    "        raise TypeError(f\"Unexpected geometry type: {type(geom)}\")\n",
    "\n",
    "# Apply conversion function to the 'geometry' column\n",
    "selected_df2['geometry_wkt'] = selected_df2['geometry'].apply(convert_wkb_to_wkt)\n",
    "\n",
    "# Connect to the database (replace with your actual database URI)\n",
    "# Create an engine and connect to the PostgreSQL database\n",
    "engine = create_engine(f'postgresql+psycopg2://{user}:{password}@{host}:5432/{db_name}')\n",
    "\n",
    "# Create the table\n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "# Create a session to interact with the database\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# Iterate over the rows in the DataFrame and insert them into the database\n",
    "for index, row in selected_df2.iterrows():\n",
    "    dataset_entry = Dataset(\n",
    "         cod_reg=row['cod_reg'],\n",
    "        cod_rip=row['cod_rip'],\n",
    "        cod_prov=row['COD_PROV'],\n",
    "        ar_kmq=row['ar_kmq'],\n",
    "        nome=row['nome'],\n",
    "        uid=row['uid'],\n",
    "        ar_fr_p3p4=row['ar_fr_p3p4'],\n",
    "        ar_fr_p2=row['ar_fr_p2'],\n",
    "        ar_fr_p1=row['ar_fr_p1'],\n",
    "        ar_fr_p3=row['ar_fr_p3'],\n",
    "        ar_fr_p4=row['ar_fr_p4'],\n",
    "        ar_fr_aa=row['ar_fr_aa'],\n",
    "        ar_frp3p4p=row['ar_frp3p4p'],\n",
    "        ar_frp4_p=row['ar_frp4_p'],\n",
    "        ar_frp3_p=row['ar_frp3_p'],\n",
    "        ar_frp2_p=row['ar_frp2_p'],\n",
    "        ar_frp1_p=row['ar_frp1_p'],\n",
    "        ar_fraa_p=row['ar_fraa_p'],\n",
    "        pop_fr_p2=row['pop_fr_p2'],\n",
    "        pop_fr_p1=row['pop_fr_p1'],\n",
    "        pop_fr_p3=row['pop_fr_p3'],\n",
    "        pop_fr_p4=row['pop_fr_p4'],\n",
    "        popfr_p3p4=row['popfr_p3p4'],\n",
    "        pop_fr_aa=row['pop_fr_aa'],\n",
    "        popfrp4_p=row['popfrp4_p'],\n",
    "        popfrp3_p=row['popfrp3_p'],\n",
    "        popfrp2_p=row['popfrp2_p'],\n",
    "        popfrp1_p=row['popfrp1_p'],\n",
    "        popfrp3p4p=row['popfrp3p4p'],\n",
    "        popfraa_p=row['popfraa_p'],\n",
    "        ed_fr_p4=row['ed_fr_p4'],\n",
    "        ed_fr_p3=row['ed_fr_p3'],\n",
    "        ed_fr_p2=row['ed_fr_p2'],\n",
    "        ed_fr_p1=row['ed_fr_p1'],\n",
    "        ed_fr_p3p4=row['ed_fr_p3p4'],\n",
    "        edfrp3p4p=row['edfrp3p4p'],\n",
    "        geometry=row['geometry_wkt']  # Insert WKT geometry\n",
    "    )\n",
    "    session.add(dataset_entry)\n",
    "    \n",
    "# Commit the session to save the changes in the database\n",
    "try:\n",
    "    session.commit()\n",
    "except Exception as e:\n",
    "    session.rollback() # Rollback the session in case of an error\n",
    "    print(f\"Error committing session: {e}\")\n",
    "finally:\n",
    "    session.close() # Close the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6374f22-3dc8-4727-a961-77b731a92d08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
