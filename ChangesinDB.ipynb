{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187e6e8a-0915-47c9-a1dd-e3e73980956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, Column, Integer, String, Float\n",
    "from config import db_name, user, password, host\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from geoalchemy2 import Geometry\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely import wkt\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d38454a-7ffd-482f-a070-d1e1692a6297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d978c64f-15d0-4bbc-ba18-6dd6ce753bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install GeoAlchemy2 SQLAlchemy psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b846d530-90e2-47e3-bcc8-47da7cd5e9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send the request\n",
    "def jason2dataf(url):\n",
    "    response = requests.get(url)\n",
    "    response\n",
    "    # store the raw text of the response in a variable\n",
    "    raw_data = response.text\n",
    "    raw_data\n",
    "    # parse the raw text response into a JSON\n",
    "    data = json.loads(raw_data)\n",
    "    data\n",
    "    # from JSON to Pandas DataFrame\n",
    "    data_df = pd.json_normalize(data)\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda643da-89be-439b-86e2-b86aff4149ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataf_liguria = jason2dataf('https://test.idrogeo.isprambiente.it/api/pir/regioni/7')\n",
    "dataf_lombardia = jason2dataf('https://test.idrogeo.isprambiente.it/api/pir/regioni/3')\n",
    "#dataf_Piemonte = jason2dataf('https://test.idrogeo.isprambiente.it/api/pir/regioni/1')\n",
    "#dataf_valle = jason2dataf('https://test.idrogeo.isprambiente.it/api/pir/regioni/2')\n",
    "data_prov_milan = jason2dataf('https://test.idrogeo.isprambiente.it/api/pir/province/15')\n",
    "data_prov_varese = jason2dataf('https://test.idrogeo.isprambiente.it/api/pir/province/12')\n",
    "data_prov_como = jason2dataf('https://test.idrogeo.isprambiente.it/api/pir/province/13')\n",
    "data_prov_lecco = jason2dataf('https://test.idrogeo.isprambiente.it/api/pir/province/97')\n",
    "data_prov_sondrio = jason2dataf('https://test.idrogeo.isprambiente.it/api/pir/province/14')\n",
    "data_prov_bergamo = jason2dataf('https://test.idrogeo.isprambiente.it/api/pir/province/16')\n",
    "data_prov_brescia = jason2dataf('https://test.idrogeo.isprambiente.it/api/pir/province/17')\n",
    "data_prov_pavia = jason2dataf('https://test.idrogeo.isprambiente.it/api/pir/province/18')\n",
    "data_prov_cremona = jason2dataf('https://test.idrogeo.isprambiente.it/api/pir/province/19')\n",
    "data_prov_mantova = jason2dataf('https://test.idrogeo.isprambiente.it/api/pir/province/20')\n",
    "data_prov_lodi = jason2dataf('https://test.idrogeo.isprambiente.it/api/pir/province/98')\n",
    "data_prov_Monza = jason2dataf('https://test.idrogeo.isprambiente.it/api/pir/province/108')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e818c8ed-2ab7-4820-b001-98134f0dfe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames\n",
    "merged_df = pd.concat([data_prov_milan, data_prov_varese,data_prov_como,data_prov_lecco,data_prov_sondrio,data_prov_bergamo,data_prov_brescia,data_prov_pavia,data_prov_cremona,data_prov_mantova,data_prov_lodi,data_prov_Monza]).reset_index(drop=True)\n",
    "\n",
    "# Display the merged DataFrame\n",
    "merged_df.rename(columns={'cod_prov':'COD_PROV'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57c3a12-007d-4bd9-a9fe-043f4efecb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefile_path_region = \"./Limiti01012024_g/Reg01012024_g/Reg01012024_g_WGS84.shp\"\n",
    "shapefile_path_province = \"./Limiti01012024_g/ProvCM01012024_g/ProvCM01012024_g_WGS84.shp\"\n",
    "gdf_region = gpd.read_file(shapefile_path_region)\n",
    "gdf_province = gpd.read_file(shapefile_path_province)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c50bbe-6c91-460c-bfc6-67b6cce0a2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "desired_cod_RIP = [15,12,13,97,14,16,17,18,19,20,98,108]\n",
    "\n",
    "# Filter the GeoDataFrame based on the desired cod_RIP values\n",
    "filtered_gdf = gdf_province[gdf_province['COD_PROV'].isin(desired_cod_RIP)]\n",
    "\n",
    "# Display the filtered DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e9e4b9-d668-47ee-acfa-cb81a162ff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_cod_REG = [3]\n",
    "\n",
    "# Filter the GeoDataFrame based on the desired cod_RIP values\n",
    "filtered_gdf2 = filtered_gdf[filtered_gdf['COD_RIP'].isin(desired_cod_REG)]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(filtered_gdf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2c7b69-96a7-4fa5-bd45-9a4e9541f898",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df2 = merged_df.merge(filtered_gdf[['COD_PROV', 'geometry']], on='COD_PROV', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501e042c-2f8d-418d-90d0-667e1339d9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_select = ['geometry','cod_reg','cod_rip','COD_PROV','ar_kmq','nome','uid',\n",
    "    'ar_fr_p3p4', 'ar_fr_p2', 'ar_fr_p1', \n",
    "    'pop_fr_p2', 'pop_fr_p1', \n",
    "    'ed_fr_p2', 'ed_fr_p1', \n",
    "    'ar_frp3p4p', 'popfrp3p4p', \n",
    "    'ed_fr_p3p4', 'edfrp3p4p'\n",
    "]\n",
    "\n",
    "# Select the columns\n",
    "selected_df = merged_df2[columns_to_select]\n",
    "selected_df2 = selected_df.copy()\n",
    "type(selected_df2['geometry'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ed99b8-3d45-4f60-86e9-d8e38033a6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Database connection parameters\n",
    "# with open('config.py', 'w') as f:\n",
    "#     f.write(db_name = input(f'Enter the database name for the postgres:\\n'))\n",
    "#     f.write(user = input(f'Enter the user for the postgres:\\n'))\n",
    "#     f.write(password = input(f'Enter the Password for the postgres:\\n'))\n",
    "#     f.write(host = input(f'Enter the host for the postgres:\\n'))\n",
    "\n",
    "# db_name = \"project\"\n",
    "# user = \"postgres\"\n",
    "# password = \"admin\"\n",
    "# host = \"localhost\"\n",
    "print (db_name, user, password, host)\n",
    "# db_name = \"project\"\n",
    "# user = \"postgres\"\n",
    "# password = \"admin\"\n",
    "# host = \"localhost\"\n",
    "\n",
    "# Connect to the default database to create the new database\n",
    "conn = psycopg2.connect(dbname=\"postgres\", user=user, password=password, host=host)\n",
    "conn.autocommit = True # needed to create a db programmatically\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create the database\n",
    "try:\n",
    "    cursor.execute(f\"CREATE DATABASE {db_name};\")\n",
    "except: pass\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23973db6-ca34-4b5d-bd30-8f2e740e26d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.wkb import loads as wkb_loads\n",
    "from shapely.wkt import dumps as wkt_dumps\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import Column, Integer, String, Text, create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "# Define the Base class for SQLAlchemy\n",
    "Base = declarative_base()\n",
    "\n",
    "# Define your SQLAlchemy model\n",
    "class Dataset(Base):\n",
    "    __tablename__ = 'dataset'\n",
    "\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    cod_reg = Column(Integer)\n",
    "    cod_rip = Column(Integer)\n",
    "    cod_prov = Column(Integer)\n",
    "    ar_kmq = Column(Integer)\n",
    "    nome = Column(String)\n",
    "    uid = Column(Integer)\n",
    "    ar_fr_p3p4 = Column(Integer)\n",
    "    ar_fr_p2 = Column(Integer)\n",
    "    ar_fr_p1 = Column(Integer)\n",
    "    pop_fr_p2 = Column(Integer)\n",
    "    pop_fr_p1 = Column(Integer)\n",
    "    ed_fr_p2 = Column(Integer)\n",
    "    ed_fr_p1 = Column(Integer)\n",
    "    ar_frp3p4p = Column(Integer)\n",
    "    popfrp3p4p = Column(Integer)\n",
    "    ed_fr_p3p4 = Column(Integer)\n",
    "    edfrp3p4p = Column(Integer)\n",
    "    geometry = Column(Text)  # Assuming you're storing geometry as WKT in a text column\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<Dataset(id={self.id}, nome='{self.nome}')>\"\n",
    "\n",
    "# Function to convert WKB to WKT\n",
    "def convert_wkb_to_wkt(geom):\n",
    "    if isinstance(geom, str):\n",
    "        geom = bytes.fromhex(geom)  # Convert hex string to bytes\n",
    "    if isinstance(geom, (bytes, bytearray)):\n",
    "        return wkt_dumps(wkb_loads(geom))  # Convert WKB to Shapely geometry, then to WKT\n",
    "    elif isinstance(geom, (MultiPolygon, Polygon)):\n",
    "        return wkt_dumps(geom)  # If it's already a Shapely geometry, convert directly to WKT\n",
    "    else:\n",
    "        raise TypeError(f\"Unexpected geometry type: {type(geom)}\")\n",
    "\n",
    "# Apply conversion function to the 'geometry' column\n",
    "selected_df2['geometry_wkt'] = selected_df2['geometry'].apply(convert_wkb_to_wkt)\n",
    "\n",
    "# Print the type of the first geometry to confirm conversion\n",
    "print(type(selected_df2['geometry_wkt'].iloc[0]))  # Should be <class 'str'>\n",
    "print(selected_df2['geometry_wkt'].head())  # Optionally, check the first few rows\n",
    "\n",
    "# Connect to the database (replace with your actual database URI)\n",
    "# Create an engine and connect to the PostgreSQL database\n",
    "engine = create_engine(f'postgresql+psycopg2://{user}:{password}@{host}:5432/{db_name}')\n",
    "\n",
    "# Create the table\n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "# Inserting Data into the Database\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "for index, row in selected_df2.iterrows():\n",
    "    dataset_entry = Dataset(\n",
    "        cod_reg=row['cod_reg'],\n",
    "        cod_rip=row['cod_rip'],\n",
    "        cod_prov=row['COD_PROV'],\n",
    "        ar_kmq=row['ar_kmq'],\n",
    "        nome=row['nome'],\n",
    "        uid=row['uid'],\n",
    "        ar_fr_p3p4=row['ar_fr_p3p4'],\n",
    "        ar_fr_p2=row['ar_fr_p2'],\n",
    "        ar_fr_p1=row['ar_fr_p1'],\n",
    "        pop_fr_p2=row['pop_fr_p2'],\n",
    "        pop_fr_p1=row['pop_fr_p1'],\n",
    "        ed_fr_p2=row['ed_fr_p2'],\n",
    "        ed_fr_p1=row['ed_fr_p1'],\n",
    "        ar_frp3p4p=row['ar_frp3p4p'],\n",
    "        popfrp3p4p=row['popfrp3p4p'],\n",
    "        ed_fr_p3p4=row['ed_fr_p3p4'],\n",
    "        edfrp3p4p=row['edfrp3p4p'],\n",
    "        geometry=row['geometry_wkt']  # Insert WKT geometry\n",
    "    )\n",
    "    session.add(dataset_entry)\n",
    "\n",
    "try:\n",
    "    session.commit()\n",
    "except Exception as e:\n",
    "    session.rollback()\n",
    "    print(f\"Error committing session: {e}\")\n",
    "finally:\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfa7b3f-b200-4b89-8626-f6dac09e53b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aae87a4-3b9c-4335-a502-84acba09f685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86803acc-7155-4e7d-8191-ffea321c6a41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a7053e-1b7d-47b3-b2f6-9a01e74d5704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2023cd-d59c-45e2-a13c-123d4c017a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59a1aa6-0ba7-47ec-a124-2913ba1958f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8daf54b-8f72-43b9-b108-824051d8fa95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcfd21d-f31d-4f26-bb6d-f59c2fae83c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d732316-128d-48ea-b0e5-59507c5f9308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a320d9b8-a244-44bf-bda8-c4e92e2c8932",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
